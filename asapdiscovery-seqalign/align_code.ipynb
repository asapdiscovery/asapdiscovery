{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for sequence and structural alignment of related proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# BioPython \n",
    "from Bio.Seq import Seq\n",
    "from Bio import AlignIO, SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import sys, requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bokeh imports\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, Plot, Grid, Range1d\n",
    "from bokeh.models.glyphs import Text, Rect\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import output_file, save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Sequence alignment \n",
    "BLAST-Mafft-Bokeh implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---This implementation needs the installation of both Bokeh and also the command-line mafft program---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining colors for each protein residue\n",
    "def get_colors_protein(seqs):\n",
    "    \"\"\"Make colors for bases in sequence\n",
    "\n",
    "    Args:\n",
    "        seqs (list, str): List or string with protein sequence\n",
    "\n",
    "    Returns:\n",
    "        list: List with colors\n",
    "    \"\"\"\n",
    "    text = [i for s in list(seqs) for i in s]\n",
    "    aa_colors = {\n",
    "    'A': 'red',    # Alanine\n",
    "    'R': 'blue',   # Arginine\n",
    "    'N': 'green',  # Asparagine\n",
    "    'D': 'yellow', # Aspartic acid\n",
    "    'C': 'orange', # Cysteine\n",
    "    'Q': 'purple', # Glutamine\n",
    "    'E': 'cyan',   # Glutamic acid\n",
    "    'G': 'magenta',# Glycine\n",
    "    'H': 'pink',   # Histidine\n",
    "    'I': 'brown',  # Isoleucine\n",
    "    'L': 'gray',   # Leucine\n",
    "    'K': 'lime',   # Lysine\n",
    "    'M': 'teal',   # Methionine\n",
    "    'F': 'navy',   # Phenylalanine\n",
    "    'P': 'olive',  # Proline\n",
    "    'S': 'maroon', # Serine\n",
    "    'T': 'silver', # Threonine\n",
    "    'W': 'gold',   # Tryptophan\n",
    "    'Y': 'skyblue',# Tyrosine\n",
    "    'V': 'violet', # Valine\n",
    "    '-':'white'\n",
    "    }\n",
    "    colors = [aa_colors[i] for i in text]\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_alignment_bokeh(aln, fontsize=\"9pt\", plot_width=800, file_name='alignment'):\n",
    "    \"\"\"Bokeh sequence alignment view\n",
    "    From: https://dmnfarrell.github.io/bioinformatics/bokeh-sequence-aligner\"\"\"\n",
    "    # The function takes a biopython alignment object as input.\n",
    "    # rec is the alignment record: Each one of the entries given as input\n",
    "    seqs = [rec.seq for rec in (aln)] # Each sequence input\n",
    "    ids = [rec.id for rec in aln] # Each entry ID\n",
    "    text = [i for s in list(seqs) for i in s] #Al units joind on same list\n",
    "    # List with ALL colors\n",
    "    colors = get_colors_protein(seqs)    \n",
    "    N = len(seqs[0]) # What if they're not the same length???\n",
    "    S = len(seqs)    \n",
    "    width = .4\n",
    "\n",
    "    x = np.arange(1,N+1)\n",
    "    y = np.arange(0,S,1)\n",
    "    #creates a 2D grid of coords from the 1D arrays\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    #flattens the arrays\n",
    "    gx = xx.ravel()\n",
    "    gy = yy.flatten()\n",
    "    #use recty for rect coords with an offset\n",
    "    recty = gy+.5 # Just to make the rectangles twice the size and the letter in the middle\n",
    "    h= 1/S\n",
    "    #now we can create the ColumnDataSource with all the arrays\n",
    "    print(f'Aligning {S} sequences of lenght {N}')\n",
    "    # ColumnDataSource is a JSON dict that maps names to arrays of values\n",
    "    source = ColumnDataSource(dict(x=gx, y=gy, recty=recty, text=text, colors=colors))\n",
    "    plot_height = len(seqs)*10+50\n",
    "    x_range = Range1d(0, N+1, bounds='auto') # (start, end)\n",
    "    if N>150:\n",
    "        viewlen=150\n",
    "    else:\n",
    "        viewlen=N\n",
    "    #view_range is for the close up view\n",
    "    view_range = (0,viewlen)\n",
    "    tools=\"xpan, xwheel_zoom, reset, save\"\n",
    "\n",
    "    #entire sequence view (no text, with zoom)\n",
    "    p = figure(title=None, width=plot_width, height=plot_height,\n",
    "               x_range=x_range, y_range=(0,S), tools=tools,\n",
    "               min_border=0, toolbar_location='below')\n",
    "    # Rect simply places rectangles of wifth \"width\" into the positions defined by x and y\n",
    "    rects = Rect(x=\"x\", y=\"recty\",  width=1, height=1, fill_color=\"colors\",\n",
    "                 line_color=None, fill_alpha=0.6)\n",
    "    # Source does mapping from keys in rects to values in ColumnDataSource definition\n",
    "    p.add_glyph(source, rects) \n",
    "    p.yaxis.visible = False\n",
    "    p.grid.visible = False  \n",
    "\n",
    "    #sequence text view with ability to scroll along x axis\n",
    "    p1 = figure(title=None, width=plot_width, height=plot_height,\n",
    "                x_range=view_range, y_range=ids, tools=\"xpan,reset\",\n",
    "                min_border=0, toolbar_location='below')#, lod_factor=1)   \n",
    "    # Text does the same thing as rectangles but placing letter (or words) instead, aligned accordingly   \n",
    "    glyph = Text(x=\"x\", y=\"y\", text=\"text\", text_align='center',text_color=\"black\",\n",
    "                text_font=\"monospace\",text_font_size=fontsize)\n",
    "    rects = Rect(x=\"x\", y=\"recty\",  width=1, height=1, fill_color=\"colors\",\n",
    "                line_color=None, fill_alpha=0.4)\n",
    "    p1.add_glyph(source, glyph)\n",
    "    p1.add_glyph(source, rects)\n",
    "\n",
    "    p1.grid.visible = True\n",
    "    p1.xaxis.major_label_text_font_style = \"bold\"\n",
    "    p1.yaxis.major_label_text_font_style = \"bold\"\n",
    "    p1.yaxis.minor_tick_line_width = 0\n",
    "    p1.yaxis.major_tick_line_width = 0\n",
    "\n",
    "    p = gridplot([[p],[p1]], toolbar_location='below')\n",
    "\n",
    "    output_file(filename=f\"{file_name}.html\", title=\"Alignment result\")\n",
    "    save(p)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing alignment with two sequences of equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning 2 sequences of lenght 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text_font='monospace' [no close matches] {renderer: GlyphRenderer(id='p1062', ...)}\n"
     ]
    }
   ],
   "source": [
    "# Note here: The aminoacid sequences must be the same length, with missing units represented as '-'\n",
    "aln = AlignIO.read('covid.aln','fasta')\n",
    "p = view_alignment_bokeh(aln, plot_width=1500, file_name='simple_alignment')\n",
    "# pn.pane.Bokeh(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence alignment of BLAST sequences\n",
    "*Input reference sequence on BLAST to query for similar sequences, select seqs in the output to finally generate an HTML file with multi seq alignment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_blast(results_file, verbose):\n",
    "    # Parse results\n",
    "    E_VALUE_THRESH = 1e-20 \n",
    "\n",
    "    matches_seq = []\n",
    "    matches_id = []\n",
    "    scores = []\n",
    "\n",
    "    for record in NCBIXML.parse(open(results_file)): \n",
    "        if record.alignments: \n",
    "            if verbose:\n",
    "                print(\"\\n\") \n",
    "                print(\"query: %s\" % record.query[:100]) \n",
    "            query_seqs = []\n",
    "            query_ids = []\n",
    "            query_scores = []\n",
    "            for align in record.alignments: \n",
    "                for hsp in align.hsps: \n",
    "                    if hsp.expect < E_VALUE_THRESH: \n",
    "                        # Print sequence identity, title, and gapless sequence substring that aligns\n",
    "                        hsps0 = align.hsps[0]\n",
    "                        sequence_to_model = hsps0.sbjct.replace('-','')\n",
    "                        pidentity = round(100.0 * hsps0.identities / (hsps0.query_end-hsps0.query_start+1), 2)\n",
    "                        if verbose:\n",
    "                            print(f'length {hsps0.identities}, score {pidentity}: {align.title}')# {sequence_to_model}')\n",
    "                        query_seqs.append(sequence_to_model)\n",
    "                        query_ids.append(align.title)\n",
    "                        query_scores.append(pidentity)\n",
    "        matches_seq.append(query_seqs)\n",
    "        matches_id.append(query_ids)\n",
    "        scores.append(query_scores)\n",
    "\n",
    "    return matches_seq, matches_id, scores\n",
    "\n",
    "def get_blast_seqs(seq_source, input_type=\"fasta\", save_file=\"results.xml\", nalign=500, database=\"refseq_protein\", verbose=True):\n",
    "    \"\"\"Run a BLAST search on a protein sequence.\n",
    "    Args:\n",
    "        seq_source (string, list): Source with the sequence.\n",
    "        input_type (str, optional): Type of sequence source [\"pre-cal\", \"fasta\", \"sequence\"]. Defaults to \"fasta\".\n",
    "        save_file (str, optional): Name of output file storing BLAST results. Defaults to \"results.xml\".\n",
    "\n",
    "    Returns:\n",
    "        (list, list): Matched sequences, Matched IDs\n",
    "    \"\"\"\n",
    "    \n",
    "    if input_type == \"pre-calc\":\n",
    "        matches_seq, matches_id, scores = parse_blast(seq_source, verbose)\n",
    "        return matches_seq, matches_id, scores\n",
    "    elif input_type == \"fasta\":\n",
    "        # Input is file name\n",
    "        sequence = open(seq_source).read() \n",
    "    elif input_type == \"sequence\":\n",
    "        # Input is sequence\n",
    "        sequence = seq_source\n",
    "    else: # Another source?\n",
    "        return\n",
    "    \n",
    "    # Retrieve blastp results\n",
    "    program = 'blastp' # protein sequence BLAST\n",
    "    database =  database # non-redundant protein database\n",
    "    alignments = nalign # number of alignments to retrieve\n",
    "    result_handle = NCBIWWW.qblast(program, database, sequence, alignments=alignments) \n",
    "\n",
    "    with open(save_file, 'w') as file: \n",
    "        blast_results = result_handle.read() \n",
    "        file.write(blast_results)\n",
    "\n",
    "    matches_seq, matches_id, scores = parse_blast(save_file, verbose)\n",
    "\n",
    "    return matches_seq, matches_id, scores\n",
    "\n",
    "def process_align_data(input_alignment, output_file):\n",
    "    ''' Modify sequences in multi-seq alignment to remove gap characters '-' \n",
    "    '''\n",
    "    alignment = SeqIO.parse(input_alignment, \"fasta\")\n",
    "    filtered_sequences = []\n",
    "    for rec in alignment:\n",
    "        # Remove gap characters '-' from the sequence\n",
    "        print(rec.seq)\n",
    "        filtered_sequence = ''.join(char for char in rec.seq if char != '-')#rec.seq.ungap(\"-\")\n",
    "        # Update SeqRecord with the filtered sequence\n",
    "        filtered_seq_record = SeqRecord(filtered_sequence, id=rec.id, description=rec.description)\n",
    "        filtered_sequences.append(filtered_seq_record)\n",
    "\n",
    "    SeqIO.write(filtered_sequences, output_file, \"fasta\")\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "query: MERS-CoV Mpro\n",
      "length 301, score 100.0: ref|YP_007188578.1| ORF1a polyprotein [Betacoronavirus England 1]\n",
      "length 301, score 100.0: ref|YP_009047203.1| 1A polyprotein [Middle East respiratory syndrome-related coronavirus]\n",
      "length 301, score 100.0: ref|YP_007188577.3| ORF1ab polyprotein [Betacoronavirus England 1]\n",
      "length 301, score 100.0: ref|YP_009047202.1| 1AB polyprotein [Middle East respiratory syndrome-related coronavirus]\n",
      "length 301, score 100.0: ref|YP_009047217.1| nsp5 protein [Middle East respiratory syndrome-related coronavirus] >ref|YP_009047233.1| nsp5 protein [Middle East respiratory syndrome-related coronavirus] >ref|YP_009944285.1| nsp5 [Betacoronavirus England 1] >ref|YP_009944296.1| nsp5 [Betacoronavirus England 1]\n",
      "length 288, score 95.68: ref|YP_009361855.1| ORF1a polyprotein [Bat coronavirus]\n",
      "length 288, score 95.68: ref|YP_009361856.2| ORF1ab polyprotein [Bat coronavirus]\n",
      "length 248, score 82.39: ref|YP_009944343.1| nsp5 [Pipistrellus bat coronavirus HKU5] >ref|YP_009944358.1| nsp5 [Pipistrellus bat coronavirus HKU5]\n",
      "length 243, score 80.73: ref|YP_009944314.1| nsp5 [Tylonycteris bat coronavirus HKU4] >ref|YP_009944329.1| nsp5 [Tylonycteris bat coronavirus HKU4]\n",
      "length 248, score 82.39: ref|YP_009944337.1| ORF1a polyprotein [Pipistrellus bat coronavirus HKU5]\n",
      "length 248, score 82.39: ref|YP_001039961.1| ORF1ab polyprotein [Pipistrellus bat coronavirus HKU5]\n",
      "length 243, score 80.73: ref|YP_009944308.1| ORF1a polyprotein [Tylonycteris bat coronavirus HKU4]\n",
      "length 243, score 80.73: ref|YP_001039952.1| ORF1ab polyprotein [Tylonycteris bat coronavirus HKU4]\n",
      "length 237, score 78.74: ref|YP_009513009.1| ORF1a polyprotein [Betacoronavirus Erinaceus/VMC/DEU/2012]\n",
      "length 237, score 78.74: ref|YP_009513008.1| ORF1ab polyprotein [Betacoronavirus Erinaceus/VMC/DEU/2012]\n",
      "length 165, score 55.0: ref|YP_009924361.1| nsp5 [Rat coronavirus Parker] >ref|YP_009924372.1| nsp5 [Rat coronavirus Parker]\n",
      "length 164, score 54.67: ref|YP_209248.1| nsp5 or 3CLpro [Murine hepatitis virus strain JHM]\n",
      "length 164, score 54.67: ref|YP_009944273.1| nsp5 [Human coronavirus HKU1] >ref|YP_459936.1| nsp5 [Human coronavirus HKU1]\n",
      "length 160, score 53.33: ref|YP_009924413.1| nsp5 [Rabbit coronavirus HKU14] >ref|YP_009944258.1| nsp5 [Rabbit coronavirus HKU14]\n",
      "length 160, score 53.33: ref|YP_009915677.1| nsp5 [Murine hepatitis virus] >ref|YP_009915692.1| nsp5 [Murine hepatitis virus] >ref|YP_009924335.1| nsp5 [Murine hepatitis virus] >ref|YP_009924346.1| nsp5 [Murine hepatitis virus]\n",
      "length 160, score 53.33: ref|YP_009555250.1| nsp2 [Human coronavirus OC43] >ref|YP_009924323.1| nsp5 [Human coronavirus OC43]\n",
      "length 157, score 52.51: ref|NP_828863.1| nsp5 [SARS coronavirus Tor2] >ref|YP_009944370.1| nsp5 [SARS coronavirus Tor2]\n",
      "length 154, score 51.51: ref|YP_009725301.1| 3C-like proteinase [Severe acute respiratory syndrome coronavirus 2] >ref|YP_009742612.1| 3C-like proteinase [Severe acute respiratory syndrome coronavirus 2]\n",
      "length 154, score 51.16: ref|YP_009924387.1| nsp5 [Rousettus bat coronavirus HKU9]\n",
      "length 165, score 55.0: ref|YP_003029845.1| ORF1a polyprotein [Rat coronavirus Parker]\n",
      "length 165, score 55.0: ref|YP_003029844.1| ORF1ab polyprotein [Rat coronavirus Parker]\n",
      "length 164, score 54.67: ref|YP_209230.1| ORF1a polyprotein [Murine hepatitis virus strain JHM]\n",
      "length 164, score 54.67: ref|YP_209229.2| ORF1ab polyprotein [Murine hepatitis virus strain JHM]\n",
      "length 164, score 54.67: ref|YP_009944268.1| ORF1a polyprotein [Human coronavirus HKU1]\n",
      "length 164, score 54.67: ref|YP_173236.1| ORF1ab polyprotein [Human coronavirus HKU1]\n",
      "length 160, score 53.33: ref|YP_009944253.1| ORF1a polyprotein [Rabbit coronavirus HKU14]\n",
      "length 160, score 53.33: ref|YP_005454239.1| ORF1ab polyprotein [Rabbit coronavirus HKU14]\n",
      "length 160, score 53.33: ref|YP_009755832.1| ORF1ab polyprotein [Rodent coronavirus]\n",
      "length 160, score 53.33: ref|YP_009944265.1| ORF1a polyprotein [Rodent coronavirus]\n",
      "length 161, score 53.67: ref|NP_150074.1| orf1a polyprotein [Bovine coronavirus]\n",
      "length 161, score 53.67: ref|NP_150073.3| orf1ab polyprotein [Bovine coronavirus]\n",
      "length 160, score 53.33: ref|NP_045299.2| ORF1ab polyprotein [Murine hepatitis virus]\n",
      "length 160, score 53.33: ref|NP_045298.1| ORF1a polyprotein [Murine hepatitis virus]\n",
      "length 160, score 53.33: ref|YP_009924317.1| ORF1a polyprotein [Human coronavirus OC43]\n",
      "length 160, score 53.33: ref|YP_009824979.1| ORF1a polyprotein [Murine hepatitis virus]\n",
      "length 160, score 53.33: ref|YP_009555238.1| ORF1ab polyprotein [Human coronavirus OC43]\n",
      "length 160, score 53.33: ref|YP_009824978.1| ORF1ab polyprotein [Murine hepatitis virus]\n",
      "length 160, score 53.33: ref|YP_009113022.1| ORF1ab polyprotein [Betacoronavirus HKU24]\n",
      "length 160, score 53.33: ref|YP_009944267.1| ORF1a polyprotein [Betacoronavirus HKU24]\n",
      "length 157, score 52.51: ref|YP_009944365.1| ORF1a polyprotein [SARS coronavirus Tor2]\n",
      "length 157, score 52.51: ref|NP_828849.7| ORF1ab polyprotein [SARS coronavirus Tor2]\n",
      "length 157, score 52.51: ref|YP_010229071.1| ORF1a polyprotein [Bat coronavirus BM48-31/BGR/2008]\n",
      "length 157, score 52.51: ref|YP_003858583.1| ORF1ab polyprotein [Bat coronavirus BM48-31/BGR/2008]\n",
      "length 154, score 51.51: ref|YP_009725295.1| ORF1a polyprotein [Severe acute respiratory syndrome coronavirus 2]\n",
      "length 154, score 51.51: ref|YP_009724389.1| ORF1ab polyprotein [Severe acute respiratory syndrome coronavirus 2]\n",
      "\n",
      "\n",
      "query: SARS-CoV-2 MPro\n",
      "length 300, score 100.0: ref|YP_009725295.1| ORF1a polyprotein [Severe acute respiratory syndrome coronavirus 2]\n",
      "length 300, score 100.0: ref|YP_009724389.1| ORF1ab polyprotein [Severe acute respiratory syndrome coronavirus 2]\n",
      "length 300, score 100.0: ref|YP_009725301.1| 3C-like proteinase [Severe acute respiratory syndrome coronavirus 2] >ref|YP_009742612.1| 3C-like proteinase [Severe acute respiratory syndrome coronavirus 2]\n",
      "length 288, score 96.0: ref|YP_009944365.1| ORF1a polyprotein [SARS coronavirus Tor2]\n",
      "length 288, score 96.0: ref|NP_828849.7| ORF1ab polyprotein [SARS coronavirus Tor2]\n",
      "length 288, score 96.0: ref|NP_828863.1| nsp5 [SARS coronavirus Tor2] >ref|YP_009944370.1| nsp5 [SARS coronavirus Tor2]\n",
      "length 282, score 94.0: ref|YP_010229071.1| ORF1a polyprotein [Bat coronavirus BM48-31/BGR/2008]\n",
      "length 282, score 94.0: ref|YP_003858583.1| ORF1ab polyprotein [Bat coronavirus BM48-31/BGR/2008]\n",
      "length 205, score 68.33: ref|YP_009915659.1| ORF1a polyprotein [Bat Hp-betacoronavirus/Zhejiang2013]\n",
      "length 205, score 68.33: ref|YP_009072438.1| ORF1ab polyprotein [Bat Hp-betacoronavirus/Zhejiang2013]\n",
      "length 156, score 52.17: ref|YP_009924387.1| nsp5 [Rousettus bat coronavirus HKU9]\n",
      "length 154, score 51.51: ref|YP_009047217.1| nsp5 protein [Middle East respiratory syndrome-related coronavirus] >ref|YP_009047233.1| nsp5 protein [Middle East respiratory syndrome-related coronavirus] >ref|YP_009944285.1| nsp5 [Betacoronavirus England 1] >ref|YP_009944296.1| nsp5 [Betacoronavirus England 1]\n",
      "length 156, score 52.17: ref|YP_009273004.1| ORF1ab polyprotein [Rousettus bat coronavirus]\n",
      "length 156, score 52.17: ref|YP_009944377.1| ORF1a polyprotein [Rousettus bat coronavirus HKU9]\n",
      "length 158, score 53.02: ref|YP_009824988.1| ORF1a polyprotein [Bat coronavirus]\n",
      "length 156, score 52.17: ref|YP_001039970.1| orf1ab polyprotein [Rousettus bat coronavirus HKU9]\n",
      "length 158, score 53.02: ref|YP_009824989.2| ORF1ab polyprotein [Bat coronavirus]\n",
      "length 152, score 50.84: ref|YP_009944343.1| nsp5 [Pipistrellus bat coronavirus HKU5] >ref|YP_009944358.1| nsp5 [Pipistrellus bat coronavirus HKU5]\n",
      "length 151, score 50.5: ref|YP_009944314.1| nsp5 [Tylonycteris bat coronavirus HKU4] >ref|YP_009944329.1| nsp5 [Tylonycteris bat coronavirus HKU4]\n",
      "length 152, score 50.84: ref|YP_009915677.1| nsp5 [Murine hepatitis virus] >ref|YP_009915692.1| nsp5 [Murine hepatitis virus] >ref|YP_009924335.1| nsp5 [Murine hepatitis virus] >ref|YP_009924346.1| nsp5 [Murine hepatitis virus]\n",
      "length 152, score 50.84: ref|YP_009924361.1| nsp5 [Rat coronavirus Parker] >ref|YP_009924372.1| nsp5 [Rat coronavirus Parker]\n",
      "length 145, score 48.49: ref|YP_009924413.1| nsp5 [Rabbit coronavirus HKU14] >ref|YP_009944258.1| nsp5 [Rabbit coronavirus HKU14]\n",
      "length 151, score 50.5: ref|YP_209248.1| nsp5 or 3CLpro [Murine hepatitis virus strain JHM]\n",
      "length 147, score 49.16: ref|YP_009944273.1| nsp5 [Human coronavirus HKU1] >ref|YP_459936.1| nsp5 [Human coronavirus HKU1]\n",
      "length 145, score 48.49: ref|YP_009555250.1| nsp2 [Human coronavirus OC43] >ref|YP_009924323.1| nsp5 [Human coronavirus OC43]\n",
      "length 154, score 51.51: ref|YP_009047203.1| 1A polyprotein [Middle East respiratory syndrome-related coronavirus]\n",
      "length 154, score 51.51: ref|YP_007188578.1| ORF1a polyprotein [Betacoronavirus England 1]\n",
      "length 154, score 51.51: ref|YP_009047202.1| 1AB polyprotein [Middle East respiratory syndrome-related coronavirus]\n",
      "length 154, score 51.51: ref|YP_007188577.3| ORF1ab polyprotein [Betacoronavirus England 1]\n",
      "length 150, score 50.17: ref|YP_009361855.1| ORF1a polyprotein [Bat coronavirus]\n",
      "length 155, score 51.84: ref|YP_009513009.1| ORF1a polyprotein [Betacoronavirus Erinaceus/VMC/DEU/2012]\n",
      "length 150, score 50.17: ref|YP_009361856.2| ORF1ab polyprotein [Bat coronavirus]\n",
      "length 155, score 51.84: ref|YP_009513008.1| ORF1ab polyprotein [Betacoronavirus Erinaceus/VMC/DEU/2012]\n",
      "length 152, score 50.84: ref|YP_009944265.1| ORF1a polyprotein [Rodent coronavirus]\n",
      "length 152, score 50.84: ref|YP_009755832.1| ORF1ab polyprotein [Rodent coronavirus]\n",
      "length 152, score 50.84: ref|YP_009944337.1| ORF1a polyprotein [Pipistrellus bat coronavirus HKU5]\n",
      "length 152, score 50.84: ref|YP_001039961.1| ORF1ab polyprotein [Pipistrellus bat coronavirus HKU5]\n",
      "length 152, score 50.84: ref|NP_045298.1| ORF1a polyprotein [Murine hepatitis virus]\n",
      "length 152, score 50.84: ref|YP_009824979.1| ORF1a polyprotein [Murine hepatitis virus]\n",
      "length 151, score 50.5: ref|YP_009944308.1| ORF1a polyprotein [Tylonycteris bat coronavirus HKU4]\n",
      "length 152, score 50.84: ref|YP_009824978.1| ORF1ab polyprotein [Murine hepatitis virus]\n",
      "length 152, score 50.84: ref|NP_045299.2| ORF1ab polyprotein [Murine hepatitis virus]\n",
      "length 151, score 50.5: ref|YP_001039952.1| ORF1ab polyprotein [Tylonycteris bat coronavirus HKU4]\n",
      "length 152, score 50.84: ref|YP_003029845.1| ORF1a polyprotein [Rat coronavirus Parker]\n",
      "length 152, score 50.84: ref|YP_003029844.1| ORF1ab polyprotein [Rat coronavirus Parker]\n",
      "length 145, score 48.49: ref|YP_009944253.1| ORF1a polyprotein [Rabbit coronavirus HKU14]\n",
      "length 145, score 48.49: ref|YP_005454239.1| ORF1ab polyprotein [Rabbit coronavirus HKU14]\n",
      "length 151, score 50.5: ref|YP_209230.1| ORF1a polyprotein [Murine hepatitis virus strain JHM]\n",
      "length 151, score 50.5: ref|YP_209229.2| ORF1ab polyprotein [Murine hepatitis virus strain JHM]\n",
      "length 148, score 49.5: ref|YP_009944267.1| ORF1a polyprotein [Betacoronavirus HKU24]\n"
     ]
    }
   ],
   "source": [
    "# Calculate homologous sequences (Comment if file has already been generated because this takes some time.\n",
    "# matches_seq, matches_id = get_blast_seqs('covid.aln', input_type=\"fasta\", save_file=\"results.xml\", nalign=500, database=\"refseq_protein\")\n",
    "\n",
    "# Retrieve pre-computed file\n",
    "matches_seq, matches_id, scores = get_blast_seqs(\"results.xml\", input_type=\"pre-calc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select sequences to visualize from a checklist with BLAST results (example for MERS-CoV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose which proteins you want to compare with the REF: \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7333a440c5c24897a107d0b8de8d0653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Checkbox(value=False, description='ORF1a polyprotein [Betacoronavirus England 1]', layout=Layoutâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from ipywidgets import Layout, Checkbox, Box\n",
    "\n",
    "items_layout = Layout(flex='1 1 auto',\n",
    "                      width='auto')    \n",
    "\n",
    "box_layout = Layout(display='flex',\n",
    "                    flex_flow='column',\n",
    "                    align_items='stretch',\n",
    "                    border='',\n",
    "                    width='80%')\n",
    "\n",
    "# We will select BLAST matches for the first sequence in the input fasta file (MERS-Cov)\n",
    "data = [(' '.join(matches_id[0][s].split(' ')[1:])) for s in range(len(matches_id[0]))]\n",
    "ref_nums = [(''.join(matches_id[0][s].split(' ')[0])) for s in range(len(matches_id[0]))]\n",
    "items = [Checkbox(description=w, layout=items_layout) for w in data]\n",
    "output = Box(children=items, layout=box_layout)\n",
    "print(\"Choose which proteins you want to compare with the REF: \\n\")\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the chosen sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nthread = 0\n",
      "nthreadpair = 0\n",
      "nthreadtb = 0\n",
      "ppenalty_ex = 0\n",
      "Warning: Only 1 sequence found.\n",
      "\n",
      "Strategy:\n",
      " FFT-NS-2 (Fast but rough)\n",
      " Progressive method (guide trees were built 2 times.)\n",
      "\n",
      "If unsure which option to use, try 'mafft --auto input > output'.\n",
      "For more information, see 'mafft --help', 'mafft --man' and the mafft page.\n",
      "\n",
      "The default gap scoring scheme has been changed in version 7.110 (2013 Oct).\n",
      "It tends to insert more gaps into gap-rich regions than previous versions.\n",
      "To disable this change, add the --leavegappyregion option.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add selected sequences to array\n",
    "# Include the Reference sequence for comparison\n",
    "selected_labels = [ref_nums[0]]#['REF']\n",
    "selected_description= [items[0].description]\n",
    "selected_seqs = [matches_seq[0][0]]\n",
    "\n",
    "for i in range(0, len(items)):\n",
    "    if items[i].value == True:\n",
    "        selected_seqs.append(matches_seq[0][i])\n",
    "        selected_labels.append(ref_nums[i])\n",
    "        selected_description.append(items[i].description)\n",
    "records = []\n",
    "for r in range(len(selected_labels)):\n",
    "    rec = SeqRecord(Seq(selected_seqs[r]), id=selected_labels[r],  description=selected_description[r])\n",
    "    records.append(rec)\n",
    "\n",
    "# Run alignment with MAFFT\n",
    "input_file = \"covid_BLAST.aln\"\n",
    "out_file = \"output.fasta\"\n",
    "SeqIO.write(records, input_file, \"fasta\")\n",
    "cmd = f\"mafft {input_file} > {out_file}\"\n",
    "subprocess.run(cmd, shell=True)\n",
    "\n",
    "align = AlignIO.read(out_file, \"fasta\")\n",
    "\n",
    "# Generate output file without gaps for later steps\n",
    "clean_output = process_align_data(out_file, \"blast_selection.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text_font='monospace' [no close matches] {renderer: GlyphRenderer(id='9bc27cd3-3eb6-4c99-ae69-5b7a48e566f3', ...)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning 1 sequences of lenght 301\n"
     ]
    }
   ],
   "source": [
    "p = view_alignment_bokeh(align, plot_width=1500, file_name='alignment_blast') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Structure alignment pipeline   \n",
    "Retrieve pdb record for selection --> Alphafold setup for seqs not in pdb database --> Structure alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve PDB for chosen sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_alphafold(seq, seq_name, file_dir):\n",
    "    ''' Generate alphafold structure of a given sequence'''\n",
    "    print(\"Alphafold has not been implemented\")\n",
    "\n",
    "    # Write CSV file for the sequence\n",
    "    import csv\n",
    "    csv_file_name = file_dir + \"mers_input.csv\"\n",
    "    with open(csv_file_name, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # Write the header\n",
    "        writer.writerow([\"id\", \"sequence\"])\n",
    "        # Write the sequence\n",
    "        writer.writerow([seq_name + \"_{}\", seq])\n",
    "    \n",
    "        return csv_file_name\n",
    "    \n",
    "def retrieve_existing_alphafold(pdb_id):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        pdb_id (_type_): _description_\n",
    "    \"\"\"\n",
    "    # First convert to uniprot\n",
    "    uniprot_id = pdb_to_uniprot(pdb_id)\n",
    "    uniprot_id = uniprot_id.lower()\n",
    "    fjson = request_alphafold(uniprot_id)\n",
    "\n",
    "    return fjson\n",
    "\n",
    "def request_rcsb_pdbid(pdb_id):\n",
    "    \"\"\" A function to request a protein entry from the rcsb API with a pdb ID\n",
    "    \"\"\"\n",
    "    requestURL = f\"https://data.rcsb.org/rest/v1/core/entry/{pdb_id}\"\n",
    "    r = requests.get(requestURL, headers={ \"Accept\" : \"application/json\"})\n",
    "    if not r.ok:\n",
    "        r.raise_for_status()\n",
    "        sys.exit()\n",
    "    return r.json()\n",
    "\n",
    "def request_alphafold(uniprot_id):\n",
    "    \"\"\"\n",
    "    A function to request a protein entry from the UniProt API (from avidome-analysis)\n",
    "    \"\"\"\n",
    "    requestURL = f\"https://alphafold.ebi.ac.uk/api/uniprot/summary/{uniprot_id}.json\"\n",
    "    print(requestURL)\n",
    "    r = requests.get(requestURL)\n",
    "    if not r.ok:\n",
    "        r.raise_for_status()\n",
    "        sys.exit()\n",
    "    return r.json()\n",
    "\n",
    "def pdb_to_uniprot(pdb_id):\n",
    "    \"\"\" With the API, will find the corresponding Uniprot ID of a PDB entry\n",
    "    \"\"\"\n",
    "    import sys, requests\n",
    "    requestURL = f\"https://www.ebi.ac.uk/pdbe/api/mappings/uniprot/{pdb_id}\"\n",
    "\n",
    "    r = requests.get(requestURL, headers={ \"Accept\" : \"application/json\"})\n",
    "    if not r.ok:\n",
    "        r.raise_for_status()\n",
    "        sys.exit()\n",
    "    \n",
    "    fjson = r.json()\n",
    "    uniprot_dic = fjson[pdb_id]['UniProt']\n",
    "    uniprot_id = next(iter(uniprot_dic))\n",
    "    return uniprot_id\n",
    "\n",
    "def check_resolution(pdb_id):\n",
    "    fjson = request_rcsb_pdbid(pdb_id)\n",
    "    return fjson['rcsb_entry_info']['resolution_combined'][0]\n",
    "\n",
    "def choose_best_pdb_entry(hits, best_match_percent):\n",
    "    ''' If a sequence have different PDB files all with the same alignment match, we choose and retrieve the one with the highest resolution'''\n",
    "    max_res = 10 # some unrealistically large number?\n",
    "    best_pdb_record = \"\"\n",
    "    for h in hits:\n",
    "        id_match = hits[h]['percent_identity']\n",
    "        if id_match == best_match_percent: \n",
    "            res = check_resolution(h)\n",
    "            if res < max_res:\n",
    "                best_pdb_record = h\n",
    "                max_res = res\n",
    "        else: # We're only interested in the entries with the max possible alignment\n",
    "            break\n",
    "    print(f\"The best PDB entry is {best_pdb_record}, with match {best_match_percent}% and res {max_res}A\")\n",
    "    return best_pdb_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDB_record():\n",
    "    def __init__(self, label:str, query_seq:str, description:str, chain:int) -> None:\n",
    "        self.label = label\n",
    "        self.description = description\n",
    "        self.seq = query_seq\n",
    "        self.chain = chain\n",
    "\n",
    "\n",
    "def retrieve_pdb(seq_file, blast_file=\"results.xml\", pre_gen=False, min_id_match=99, pdb_folder=\"pdb_search_bkp/\"):\n",
    "    ''' Retrieve the PDB record of a given sequence. Alternative solution to prody'''\n",
    "    from pathlib import Path\n",
    "    import prody\n",
    "\n",
    "    folder_for_bkps = pdb_folder\n",
    "    Path(folder_for_bkps).mkdir(parents=True, exist_ok=True)\n",
    "    record_name = f\"{folder_for_bkps}{blast_file}\"\n",
    "\n",
    "    if pre_gen: # the search was done before \n",
    "        # Check if the file exists\n",
    "        record_path = Path(record_name)\n",
    "        if not record_path.exists():\n",
    "            raise ValueError(\"pre_gen was set to True but the file does not exist. Set to False to generate the record\")\n",
    "    else:\n",
    "        # Find pdb matching given sequence\n",
    "        matches_seq, matches_id, scores = get_blast_seqs(seq_file, input_type=\"fasta\", save_file=record_name, nalign=500, database=\"pdb\", verbose=False)\n",
    "        print(\"saving in \", record_name)\n",
    "\n",
    "    # Load original sequence names and descriptors for reference\n",
    "    pdb_file_record = []\n",
    "    for seq_record in SeqIO.parse(seq_file, \"fasta\"):\n",
    "        seq_id = seq_record.id\n",
    "        seq_description = seq_record.description\n",
    "        seq_chain = int(seq_record.id.split('|')[1].split('.')[-1])\n",
    "        pdb_file_record.append(PDB_record(seq_id, seq_record.seq, seq_description, seq_chain))\n",
    "\n",
    "    # Load data \n",
    "    matches_seq, matches_id, scores = get_blast_seqs(record_name, input_type=\"pre-calc\", verbose=False)\n",
    "    # best_ids = matches_id[:,0]\n",
    "    best_scores = [max(s) for s in scores]\n",
    "    # print(f\"The best matches are '{best_ids}' with scores {best_scores}\")\n",
    "    \n",
    "    match_hits = parse_pdb_blast_results(matches_seq, matches_id, scores, min_score=min_id_match)\n",
    "\n",
    "    for i, hits in enumerate(match_hits):\n",
    "        if len(hits) == 0: # The record doesn't have a PDB with high confidence\n",
    "            filename = get_seq_alphafold(pdb_file_record[i].seq, 'some_seq', folder_for_bkps)\n",
    "            pdb_file_record[i].pdb_file = filename\n",
    "            pdb_file_record[i].pdb_id = None\n",
    "            \n",
    "        else:\n",
    "            # Return the pdb entry with the max alignment and max resolution (if there are multiple matches)\n",
    "            best_pdb_record = choose_best_pdb_entry(hits, best_scores[i])\n",
    "            filename = prody.fetchPDB(best_pdb_record, folder=folder_for_bkps)\n",
    "            subprocess.run([\"gunzip\", filename])\n",
    "            pdb_file_record[i].pdb_file = filename\n",
    "            pdb_file_record[i].pdb_id = best_pdb_record\n",
    "\n",
    "    return pdb_file_record\n",
    "\n",
    "\n",
    "def parse_pdb_blast_results(blast_seq, blast_ids, blast_scores, min_score):\n",
    "    ''' For a pdb database search extract pdb ids with a minimum score (Temp fix to prody).\n",
    "        Outputs are lists because iterables are needed for functions down the pipeline.\n",
    "    '''\n",
    "\n",
    "    assert len(blast_ids) == len(blast_scores) == len(blast_seq)\n",
    "\n",
    "    match_hits = []\n",
    "    for q in range(len(blast_ids)): # Loop over queries\n",
    "        hits = {}\n",
    "        for e in range(len(blast_ids[q])): # Loop over BLAST entries\n",
    "            if blast_scores[q][e] >= min_score:\n",
    "                raw_id = blast_ids[q][e].split('|')\n",
    "                pdb_index = raw_id.index('pdb')\n",
    "                pdb_id = raw_id[pdb_index + 1]\n",
    "\n",
    "                hits[pdb_id] = {}\n",
    "                hits[pdb_id]['percent_identity'] = blast_scores[q][e]\n",
    "                hits[pdb_id]['sequence'] = blast_seq[q][e]\n",
    "\n",
    "        match_hits.append(hits)\n",
    "\n",
    "    return match_hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block contains failed attempts of doing a BLAST search for uniprot IDs. The goal is to retrieve records from Alphafold database, which are registered with an UniprotID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_swissprot_to_uniprot(swissprot_id):\n",
    "    # Construct the URL for UniProt ID mapping service\n",
    "    url = f\"https://www.ebi.ac.uk/proteins/api/features?accession={swissprot_id}\"\n",
    "    \n",
    "    r = requests.get(url, headers={ \"Accept\" : \"application/json\"})\n",
    "    if not r.ok:\n",
    "        r.raise_for_status()\n",
    "        sys.exit()\n",
    "    \n",
    "    fjson = r.json()\n",
    "    #uniprot_dic = fjson[pdb_id]['UniProt']\n",
    "    #uniprot_id = next(iter(uniprot_dic))\n",
    "    return fjson #uniprot_id\n",
    "\n",
    "seq_file = \"test.fasta\"\n",
    "# matches_seq, matches_id, scores = get_blast_seqs(seq_file, input_type=\"fasta\", save_file=\"pdb_search_bkp/results_uniprot.xml\", nalign=500, database=\"swissprot\", verbose=False)\n",
    "\n",
    "# mapped_uniprot_ids = map_swissprot_to_uniprot(\"K9N638\")[0]\n",
    "# print(\"Mapped UniProt IDs:\", mapped_uniprot_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **NOTE** Manual implementation of PDB search was implemented because ProDy has problems with retrieving data. I'm still using ProDy to retrieve PDB files (`prody.fetchPDB`). If we're keeping this solution, it may be worth it to implement that by hand too (to minimize unnecessary package imports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best PDB entry (if any) for each alignment sequence is saved on the provided `pdb_folder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> PDB file is found in working directory (pdb_search_bkp/7xry.pdb).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best PDB entry is 7XRY, with match 100.0% and res 1.99A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gunzip: pdb_search_bkp/7xry.pdb: unknown suffix -- ignored\n",
      "@> PDB file is found in working directory (pdb_search_bkp/7xry.pdb).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best PDB entry is 7XRY, with match 100.0% and res 1.99A\n",
      "Alphafold has not been implemented\n",
      "Alphafold has not been implemented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gunzip: pdb_search_bkp/7xry.pdb: unknown suffix -- ignored\n",
      "@> PDB file is found in working directory (pdb_search_bkp/6yb7.pdb).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best PDB entry is 6YB7, with match 100.0% and res 1.25A\n",
      "Alphafold has not been implemented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gunzip: pdb_search_bkp/6yb7.pdb: unknown suffix -- ignored\n",
      "@> PDB file is found in working directory (pdb_search_bkp/6xhl.pdb).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best PDB entry is 6XHL, with match 100.0% and res 1.471A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gunzip: pdb_search_bkp/6xhl.pdb: unknown suffix -- ignored\n"
     ]
    }
   ],
   "source": [
    "clean_output = \"blast_selection.fasta\"\n",
    "pdb_file_record = retrieve_pdb(clean_output, blast_file=\"results_pdb.xml\", pre_gen=True, min_id_match=99, pdb_folder=\"pdb_search_bkp/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequence label and descriptor, query sequence, and pdb_id found in the database, are stored in the `PDB_record` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the sequence ref|YP_007188578.1| ORF1a polyprotein [Betacoronavirus England 1]: SGLVKMSHPSGDVEACMVQV..., a PDB was found matching chain 1 and saved in pdb_search_bkp/7xry.pdb.\n",
      "For the sequence ref|YP_009047203.1| 1A polyprotein [Middle East respiratory syndrome-related coronavirus]: SGLVKMSHPSGDVEACMVQV..., a PDB was found matching chain 1 and saved in pdb_search_bkp/7xry.pdb.\n",
      "For the sequence ref|YP_009944343.1|: SGLVKMAAPSGVVENCMVQV..., no PDB entry was found. Alphafold csv saved in pdb_search_bkp/mers_input.csv.\n",
      "For the sequence ref|YP_009944337.1|: SGLVKMAAPSGVVENCMVQV..., no PDB entry was found. Alphafold csv saved in pdb_search_bkp/mers_input.csv.\n",
      "For the sequence ref|YP_009725301.1| 3C-like proteinase [Severe acute respiratory syndrome coronavirus 2] >ref|YP_009742612.1| 3C-like proteinase [Severe acute respiratory syndrome coronavirus 2]: SGFRKMAFPSGKVEGCMVQV..., a PDB was found matching chain 1 and saved in pdb_search_bkp/6yb7.pdb.\n",
      "For the sequence ref|YP_009944265.1|: SGIVKMVNPTSKVEPCMVSV..., no PDB entry was found. Alphafold csv saved in pdb_search_bkp/mers_input.csv.\n",
      "For the sequence ref|NP_828849.7| ORF1ab polyprotein [SARS coronavirus Tor2]: SGFRKMAFPSGKVEGCMVQV..., a PDB was found matching chain 7 and saved in pdb_search_bkp/6xhl.pdb.\n"
     ]
    }
   ],
   "source": [
    "for rec in pdb_file_record:\n",
    "    if rec.pdb_id:\n",
    "        print(f\"For the sequence {rec.description}: {rec.seq[:20]}..., a PDB was found matching chain {rec.chain} and saved in {rec.pdb_file}.\")\n",
    "    else:\n",
    "        print(f\"For the sequence {rec.label}: {rec.seq[:20]}..., no PDB entry was found. Alphafold csv saved in {rec.pdb_file}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sequences with no associated PDB entry, \n",
    "right now the `get_seq_alphafold` function only generates the input csv file with the sequence, and ColabFold is run in lilac. Will have to integrate with the lilac workflow later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphafold has not been implemented\n",
      "Copy the files pdb_search_bkp/mers_input.csv and pdb_search_bkp/7xry.pdb to the ColabFold working directory\n"
     ]
    }
   ],
   "source": [
    "csv_file = get_seq_alphafold(pdb_file_record[1].seq, \"MERS_CoV\", \"pdb_search_bkp/\")\n",
    "print(f\"Copy the files {csv_file} and {pdb_file_record[1].pdb_file} to the ColabFold working directory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumming we already ran ColabFold and the file outputs are in the folder `pdb_search_bkp/`, we select the result with less RMSD compared to the reference.  \n",
    "The following blocks were also run on lilac, because OpenEye doesn't work on my Jupyter at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asapdiscovery.data.openeye import load_openeye_pdb, save_openeye_pdb\n",
    "from asapdiscovery.modeling.modeling import superpose_molecule\n",
    "\n",
    "def rmsd_alignment(result_pdb, ref_pdb, chain, final_pdb):\n",
    "    \"\"\"Calculate RMSD of ColabFold PDB output against a reference \n",
    "\n",
    "    Args:\n",
    "        result_pdb (str): The path to the mobile pdb\n",
    "        ref_pdb (str): The path to the reference pdb\n",
    "        chain (str): Label of chain to align\n",
    "        final_pdb (str): Path to the file to be saved\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    protein = load_openeye_pdb(result_pdb)\n",
    "    ref_protein = load_openeye_pdb(ref_pdb)\n",
    "\n",
    "    aligned_protein, rmsd = superpose_molecule(ref_protein, protein, ref_chain=chain, mobile_chain=chain)\n",
    "    pdb_aligned = save_openeye_pdb(aligned_protein, final_pdb)\n",
    "\n",
    "    return rmsd, pdb_aligned\n",
    "\n",
    "def select_best_colabfold(results_dir, seq_name, pdb_ref, chain=\"A\", final_pdb=\"aligned_protein.pdb\"):\n",
    "    \"\"\"Select the best output (repetition) from the ColabFold run based on its RMSD wrt the reference.\n",
    "\n",
    "    Args:\n",
    "        results_dir (str): The directory containing the ColabFold results.\n",
    "        seq_name (str): The name we gave to the sequence in the csv file.\n",
    "        pdb_ref (str): The path to the reference pdb.\n",
    "        chain (str): Label of chain to align.\n",
    "        final_pdb (str): Path to the file to be saved.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    from pathlib import Path\n",
    "    colab_fold_dir = results_dir\n",
    "\n",
    "    rmsds = []\n",
    "    seeds = []\n",
    "    file_seed = []\n",
    "    for file_path in Path(colab_fold_dir).glob(seq_name+\"_*_unrelaxed_rank_001_alphafold2_ptm_model_1_seed_*.pdb\"):\n",
    "        pdb_to_compare = file_path\n",
    "        seed = str(pdb_to_compare).split('_')[-1].split('.')[0]\n",
    "        rmsd, pdb = rmsd_alignment(pdb_to_compare, pdb_ref, chain, final_pdb)\n",
    "        rmsds.append(rmsd)\n",
    "        seeds.append(seed)\n",
    "        file_seed.append(file_path)\n",
    "        print(f\"RMSD for seed {seed} is {rmsd}A\")\n",
    "\n",
    "    min_rmsd = np.argmin(rmsd)\n",
    "    min_rmsd_file = file_seed[min_rmsd]\n",
    "    print(f\"Seed with less RMSD is {seeds[min_rmsd]} with RMSD {rmsds[min_rmsd]}\")\n",
    "\n",
    "    min_rmsd, final_pdb = rmsd_alignment(min_rmsd_file, pdb_ref, chain, final_pdb)\n",
    "\n",
    "    return final_pdb, min_rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_fold_dir = \"pdb_search_bkp/\"\n",
    "pdb_ref = pdb_file_record[1].pdb_file\n",
    "chain = ['A', 'B'][pdb_file_record[1].chain - 1]\n",
    "\n",
    "# Running the function on Jupyter makes the Kernel crash\n",
    "seq_name = \"MERS_Mpro\" \n",
    "# alphafold_pdb, min_rmsd = select_best_colabfold(colab_fold_dir, seq_name, pdb_ref, final_pdb=\"aligned_protein.pdb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "align",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
